{"cells":[{"cell_type":"markdown","metadata":{},"source":["<h1><b font size = \"50px\" font-color: black>Spam Detecion Filter<b></h1>"]},{"cell_type":"markdown","metadata":{},"source":["By using the dataset from https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection where they collected spam and ham messages of over 5,000+ SMS messages, we can use basic machine learning from these data to estimate if a message is spam or ham"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import math\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{},"source":["Importing the basic modules for Data Science"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["df = pd.read_csv(\"./spam.csv\", encoding='latin-1')\n","clean = df.drop(['Unnamed: 2'], axis=1)\n","clean = clean.drop(['Unnamed: 3'], axis = 1)\n","clean = clean.drop(['Unnamed: 4'], axis = 1)\n","clean.rename(columns = {'v1' : 'Category', 'v2' : 'Message'}, inplace=True)\n","clean[\"Message\"] = clean[\"Message\"].str.replace('[^a-zA-Z]',' ', regex = True)\n","clean[\"Message\"] = clean[\"Message\"].str.lower()"]},{"cell_type":"markdown","metadata":{},"source":["Getting the Database read, titling the unnamed column titles, making everything lower case for easier identification and removing all non letters, we cleaned up the data to be more easily read and analyzed"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["clean_random = clean.sample(frac=1, random_state=1)\n","train_data = clean_random[:round(len(clean_random)*0.75)].reset_index(drop=True)\n","test_data = clean_random[round(len(clean_random)*0.75):].reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{},"source":["We seperated the data into 2 sections, the training set which we use to train our models for the prediction if a message is spam or ham and the test data where we end up using seperate data to test how accuracte our model is."]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["train_data['Message'] = train_data['Message'].str.split()\n","words = []\n","for i in train_data['Message']:\n","    for word in i:\n","        words.append(word)\n","words = list(set(words))\n","word_freq = pd.DataFrame(words)\n","word_freq['#Spam'] = 0\n","word_freq['#Ham'] = 0\n","word_freq.rename(columns={word_freq.columns[0]: \"Word\" }, inplace = True)\n","for i in range(0,len(train_data['Message'])):\n","    spam_ham = train_data.iloc[i]['Category']\n","    for word in train_data.iloc[i]['Message']:\n","        location = word_freq.loc[word_freq['Word'] == word]\n","        if spam_ham == \"spam\":\n","            word_freq.at[location.index[0],'#Spam']+=1\n","        elif spam_ham == \"ham\":\n","            word_freq.at[location.index[0],'#Ham']+=1"]},{"cell_type":"markdown","metadata":{},"source":["Create a seperate database where we count for each seperate word in the training data set the number of times its in a <em>spam</em> message and the number of times its in a <em>ham</em> message."]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["word_prob = word_freq\n","total_spam = (train_data[\"Category\"]==\"spam\").sum()\n","total_ham = (train_data[\"Category\"]==\"ham\").sum()\n","word_prob[\"P(E|S)\"]= (word_prob[\"#Spam\"]+0.5)/(total_spam+1)\n","word_prob[\"P(E|Â¬S)\"]= (word_prob[\"#Ham\"]+0.5)/(total_ham+1)\n","word_prob.drop(columns=[\"#Spam\",\"#Ham\"], axis = 1, inplace=True)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.12 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"c75407a027d59d8279fdc80f39ae7e88eaf5822626513196156b9ba3e7422158"}}},"nbformat":4,"nbformat_minor":2}
